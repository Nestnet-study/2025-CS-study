2주차
* **주요 주제:**
    * **인덱스(Index):**
        * [x] 인덱스의 자료구조 (B-Tree, B+Tree).
        * [x] 클러스터형 인덱스 vs 비클러스터형 인덱스의 차이점과 동작 방식.
        * [x] 인덱스가 `SELECT` 성능은 향상시키지만 `INSERT`, `UPDATE`, `DELETE` 성능은 저하시킬 수 있는 이유.
    * **트랜잭션 격리 수준(Transaction Isolation Level):**
        * [x] `Read Uncommitted`, `Read Committed`, `Repeatable Read`, `Serializable`의 개념.
        * [x] 각 격리 수준에서 발생하는 문제점 (Dirty Read, Non-Repeatable Read, Phantom Read).
    * [ ] 페이징 쿼리
* **토론 포인트:**
    * "복합 인덱스(Composite Index)를 생성할 때, 컬럼의 순서는 왜 중요하며 어떤 기준으로 순서를 정해야 할까요?"
    * "대부분의 RDBMS가 `Read Committed`를 기본 격리 수준으로 채택하는 이유는 무엇일까요? `Repeatable Read`가 아닌 이유는 무엇일까요?"
    * 벌크 업데이트시 베스트 프랙티스는?
    - 왜 대부분의 RDBMS는 B-Tree를, 쓰기 중심의 NoSQL은 LSM-Tree를 선택했을까요

***

##### 인덱스의 자료구조 (B-Tree, B+Tree).

- ? 데이터베이스의 I/O 기본 단위인 **페이지(Page) 크기**가 B-Tree/B+Tree의 성능에 구체적으로 어떤 영향을 미칠까요? 예를 들어, 페이지 크기가 매우 크거나 작을 때 트리의 높이, 노드 분할 빈도, 그리고 전반적인 검색 효율성은 어떻게 달라질까요?
    - 트리의 높이가 커진다 -> 특정 데이터를 찾기 위해 거쳐야 할 노드가 많아지므로, **디스크 I/O 횟수가 증가**하여 검색 성능이 저하된다
        - 극단적인 예시로 이진 트리는 높이가 수십 이상으로 매우 깊어지므로, 디스크 기반 환경에서는 수십 번의 I/O가 발생해 사실상 사용이 불가능함
    - 노드의 크기가 커진다 ->
        - **불필요한 데이터 전송:** 단 하나의 키가 필요할 뿐인데, 거대한 페이지 전체를 디스크에서 메모리로 읽어와야 하므로 전송 시간이 낭비됩니다.
        - **메모리 내 검색 시간 증가:** 메모리로 가져온 거대한 페이지 안에서 원하는 키를 찾는 시간(CPU 연산)이 길어집니다.

- ? B-Tree 역시 리프 노드를 순회하면 정렬된 데이터를 얻을 수 있습니다. 그럼에도 불구하고 B+Tree가 **범위 스캔(Range Scan)**에서 B-Tree보다 월등히 효율적이라고 평가받는 이유는 무엇일까요? 두 자료구조의 디스크 I/O 패턴 차이와 관련하여 설명해 보세요.
    - **B+Tree의 범위 스캔:**
        1. 범위의 시작 값(예: `id > 100`)을 찾기 위해 루트부터 리프까지 단 한 번 탐색합니다. (예: `id=101`이 있는 리프 노드에 도달)
        2. 그 후로는 리프 노드끼리 연결된 **연결 리스트를 따라 다음 노드로 순차적으로 이동**하면 됩니다. 이는 디스크에 저장된 데이터를 순차적으로 읽는 **순차 I/O(Sequential I/O)** 패턴으로 동작하여 매우 빠릅니다.
    - **B-Tree의 범위 스캔:**
        1. B-Tree는 리프 노드 간 연결이 없습니다. 따라서 한 값을 찾은 후 다음 값을 찾으려면, **부모 노드로 다시 올라갔다가 인접한 자식 노드로 내려오는 과정**을 반복해야 합니다.
        2. 이 과정은 디스크의 여러 다른 위치에 접근하는 **임의 접근 I/O(Random I/O)**를 유발합니다. 순차 I/O에 비해 임의 접근 I/O는 디스크 헤더의 물리적인 움직임이 많아 훨씬 느립니다.

- ? 인덱스 키의 크기가 매우 클 경우(예: 긴 URL 주소를 인덱싱), B+Tree의 성능에 어떤 문제가 발생할 수 있으며, 이를 완화하기 위해 사용되는 **인덱싱 전략(예: 접두사 인덱스, Prefix Index)**은 무엇이고 어떤 원리로 동작하나요?
    - **큰 인덱스 키의 문제점:**
        1. **페이지당 저장 가능한 키 감소:** 인덱스 페이지의 크기는 고정되어 있습니다. 키(예: URL) 하나의 크기가 커지면, 한 페이지에 저장할 수 있는 키의 개수가 줄어듭니다.
        2. **팬아웃(Fan-out) 감소 및 트리 높이 증가:** 이는 곧 B+Tree의 팬아웃이 줄어드는 결과로 이어집니다. 팬아웃이 작아지면 트리의 높이가 높아지고, 결국 **검색에 필요한 디스크 I/O 횟수가 증가**하여 성능이 저하됩니다.
        3. **메모리 효율 저하:** 인덱스를 캐싱하는 버퍼 풀(Buffer Pool)의 공간을 더 많이 차지하여 메모리 효율도 떨어집니다.
    - **해결책: 접두사 인덱스 (Prefix Index)**
        - **원리:** 문자열 전체를 키로 사용하지 않고, **문자열의 앞부분 일부(prefix)만 잘라서 인덱스 키로 사용**하는 전략입니다. `CREATE INDEX idx_url ON posts(url(255));` 와 같이 길이를 지정합니다.

##### 클러스터형 인덱스 vs 비클러스터형 인덱스의 차이점과 동작 방식.

- ? 클러스터형 인덱스와 비클러스터형 인덱스에 성능 차이가 있을까? 있다면 이유가 뭘까? 
    - 비클러스터형 인덱스가 적용되어있다고 하더라도 실제 데이터는 디스크 여기저기에 흩어져있기 때문에 범위 검색 속도도 매우 느림

- ? 클러스터형 인덱스는 테이블당 하나만 존재할 수 있습니다. 그렇다면 클러스터형 인덱스가 없는 테이블(힙 테이블, Heap Table)은 어떤 경우에 유리하며, 어떤 단점을 가질까요?
    - 데이터 정렬을 하지 않고 끝에 추가만 하므로 `INSERT` 속도가 매우 빠름
    - 데이터가 정렬되어 있지 않아 특정 데이터를 찾으려면 테이블 전체를 스캔해야 하므로 `SELECT` 속도가 매우 느림

- ? MySQL의 InnoDB 스토리지 엔진에서, **보조 인덱스(비클러스터형 인덱스)**는 데이터의 물리적 주소(RID) 대신 **프라이머리 키(클러스터형 인덱스 키)**를 가지고 있습니다. 이러한 설계 방식이 가져오는 장점과 단점은 무엇일까요?
    - 장점: 데이터의 물리적 주소가 바뀌더라도 상관없다
        - **페이지 분할 (Page Split):** 정렬된 위치에 새로운 데이터가 `INSERT`될 때, 해당 페이지에 공간이 부족하면 새로운 페이지를 할당하고 기존 데이터의 일부를 옮기는 '페이지 분할'이 일어납니다. 이때 데이터의 물리적 위치가 변경됩니다.
        - **데이터 업데이트 (UPDATE):** `VARCHAR` 같은 가변 길이 컬럼의 데이터가 더 길게 수정되면, 기존 페이지에 더는 담을 수 없어 다른 페이지로 행 전체가 이동하기도 합니다.
    - 단점: PK를 물리적 주소로 다시 변환해야하는 오버헤드가 존재한다

- ? 데이터 삽입(`INSERT`) 성능 측면에서, 순차적으로 증가하는 값(예: `AUTO_INCREMENT`)을 클러스터형 인덱스 키로 사용하는 테이블과 힙 테이블 중 어느 쪽이 일반적으로 더 유리하며, 그 이유는 무엇일까요? '페이지 분할(Page Split)'과 '단편화(Fragmentation)' 개념을 사용하여 설명해 보세요.
	- 힙 테이블처럼 데이터가 마지막에 추가되므로 매우 빠릅니다. 하지만, 데이터를 추가할 때마다 **B+Tree 구조를 유지**하기 위한 약간의 추가 작업(예: 인덱스 노드의 포인터 관리 등)이 필요합니다.
	- 힙 테이블은 INSERT시 페이지 분할 작업이 아예 발생하지 않는다 (페이지 분할이란 정렬된 구조의 **중간**에 있는 특정 페이지가 꽉 찼을 때, 그 페이지를 **두 개로 쪼개고** 기존 데이터의 절반을 새 페이지로 옮기는 복잡한 작업을 의미)

- ? 테이블의 프라이머리 키(PK)는 보통 클러스터형 인덱스로 자동 생성됩니다. 만약 PK로 UUID나 주민등록번호와 같이 무작위적인(random) 문자열을 사용한다면, 순차적으로 증가하는 정수(Integer)를 PK로 사용할 때와 비교하여 어떤 성능상 불이익이 발생할 수 있을까요?
	- 마지막에 삽입된 데이터가 데이터 맨 뒤에 삽입될거라는 보장이 없기 때문에 페이지 분할 및 재배치 작업이 발생할 수 있기 때문에 INSERT 성능이 더 안 좋아지게 된다
	- `INSERT` 성능 저하 외에도 다음과 같은 문제가 발생합니다.
		- **높은 단편화 (Fragmentation):** 잦은 페이지 분할로 인해 각 데이터 페이지의 채움률(fill-factor)이 낮아져 공간이 낭비되고, 테이블 전체적으로 데이터 밀도가 떨어집니다. 
		- **보조 인덱스 비대화:** UUID(`CHAR(36)`, 36바이트)는 `BIGINT`(8바이트)보다 훨씬 큽니다. InnoDB의 보조 인덱스는 PK 값을 포함하므로, **모든 보조 인덱스의 크기가 불필요하게 커집니다.** 이는 더 많은 디스크 공간과 메모리(버퍼 풀)를 차지하게 만들어 전반적인 조회 성능까지 저하시킵니다.

- ? 그렇다면 분산 데이터베이스 환경에서는 왜 `AUTO_INCREMENT` 대신 UUID와 같은 값을 PK로 사용하는 것을 고려할까요? 전역적으로 고유한 키(Globally Unique Key)를 생성해야 하는 상황의 이점은 무엇일까요?
	- 각 서버에서 독립적으로 auto_increment 카운터를 가져가게되면 키 충돌 문제가 발생하고,
	- 이 문제를 해결하기 위해 중앙관리 방식을 선택하게 되면 단일 장애점, 성능 병목 문제가 발생한다
	- UUID를 사용하게 되면 서버 간의 의존성을 완전히 제거하여 완벽한 수평적 확장이 가능해짐
	- 설령 애플리케이션과 서버 간의 연결이 끊어진 상황에서도 선 생성 후 연결이 복구되었을때 키 충돌 문제가 발생하지 않기 때문에 동기화가 손쉽게 가능하다
	- 서로 다른 두 시스템을 병합할때에도 키 충돌이 발생하지 않으므로 손쉽게 병합이 가능하다

- ? Auto Increment vs ULID
	- 기존 UUID의 문제점을 어느정도 완화
	- 키 크기로 인해서 발생하는 보조 인덱스 비대화 문제
	- 완벽한 순차성까지는 보장되지 않는다
		- ID를 생성하는 시스템 시계에 의존적이라 **시간이 더 빠른 서버에서 생성된 ID가 논리적으로 과거의 데이터임에도 불구하고 B-Tree의 더 뒷부분에 삽입**될 수 있음
		- 동일 시간 내 무작위성으로 인해 소규모 페이지 분할 발생 가능 (다만 auto increment의 경우에는 counter를 락으로 관리하므로 성능 측면에서는 더 치명적임)

	- ! 결국 티켓팅처럼 완벽한 순차성을 보장해야하는 경우에는 결국 한 곳에서 관리할 수 밖에 없겠구나

- ? 선착순 이벤트를 구현하려면 어떻게 해야할까? ^zomt8u
	- 대기열 시스템은 **서버 최대 처리량의 70~80%에 달하는 트래픽이 예측 불가능하게 몰릴 때** 도입을 고려함 (서버 사양, 로직 복잡도에 따라 서버 최대 처리량은 천차만별)
		- 일반적으로 1000 ~ 5000 TPS
	- Redis 같은 인메모리 기반 시스템으로 대기열 시스템을 구현해서 부하가 가장 심한 줄세우기 부분만 빠르게 처리 (초당 수만~수십만 개의 요청을 처리할 수 있음)
		- ? 단순히 디스크 vs 메모리로 인한 성능 차이일까?
			- 동시성 모델의 차이도 무시못함 (복잡한 락을 거는대신 레디스는 싱글 스레드 모델로 모든 명령어를 순차적으로 처리함)
				- ! redis에서 무거운 명령어 사용에 특히나 더 유의해야하는 이유

- ? 만약 한 대의 Redis를 넘어서는 트래픽이 들어오는 경우에는 어떻게 대응할 수 있을까?
	- **1단계: 각 엣지 서버에서 1차 줄 세우기 (지역별 속도 제어)** 각 지역의 엣지 서버가 자신이 감당할 수 있는 만큼만 요청을 받아, 트래픽의 흐름을 1차적으로 제어하고 안정시킵니다. 
	- **2단계: 중앙에서 합쳐서 다시 줄 세우기 (최종 순서 확정)** 엣지를 통과한 요청들을 중앙의 샤딩된 Redis 클러스터로 모아, 그곳에 도착하는 순서대로 최종적인 단일 큐를 완성합니다.

- ? redis에서 Head-of-Line Blocking 문제를 최소화하기 위해서는?
	- **점진적인 스캔 명령어 사용 (`SCAN`)**: `KEYS` 대신 `SCAN` 명령어를 사용하면, 전체 키를 한 번에 스캔하는 대신 **커서(cursor) 기반으로 나눠서** 가져올 수 있습니다. `SCAN`은 일부 데이터와 다음 시작점을 알려주므로, 중간에 다른 명령들이 실행될 틈을 줍니다. (`HSCAN`, `SSCAN` 등도 동일)
	- **백그라운드 스레드 활용 (`UNLINK`)**: `DEL`로 큰 데이터를 삭제하면 동기적으로 처리되어 Redis가 잠시 멈출 수 있습니다. 대신 `UNLINK` 명령어를 사용하면, 키 목록에서는 즉시 삭제하고 실제 메모리 해제 작업은 **백그라운드 스레드**에 맡겨서 메인 스레드의 멈춤을 최소화합니다.
	- **데이터 모델링**: 하나의 키에 수십만 개의 데이터를 저장하는 것은 좋지 않은 설계일 수 있습니다. (List, Set 등) 데이터를 여러 개의 작은 키로 분리하여 저장하는 것이 좋습니다.    
	- **느린 명령어 모니터링 (`SLOWLOG`)**: `SLOWLOG` 기능을 활성화하면, 설정된 시간 이상으로 오래 걸리는 명령들을 기록해주어 어떤 명령이 문제를 일으키는지 쉽게 찾아낼 수 있습니다.

##### 인덱스가 `SELECT` 성능은 향상시키지만 `INSERT`, `UPDATE`, `DELETE` 성능은 저하시킬 수 있는 이유

- ? Q2. 온라인 쇼핑몰의 products 테이블이 있고, 사용자들은 category, brand, price 등 다양한 조건으로 상품을 필터링하고 정렬합니다. 동시에 stock_quantity(재고량)는 주문이 들어올 때마다 매우 빈번하게 UPDATE됩니다. 이 테이블을 위한 효과적인 인덱싱 전략을 어떻게 설계하시겠습니까? 다양한 조회 성능과 잦은 쓰기 성능 사이의 트레이드오프를 어떻게 고려해야 할까요?

##### 트랜잭션 격리 수준별 발생가능한 문제

1. Read Uncommitted -> Dirty Read 문제 발생
2. Read Commited -> Non-Repeatable Read 문제 발생
3. Repeatable Read -> Phantom Read 문제 발생
4. Serializable -> 성능 문제 발생

- ? **Q1.** 대부분의 데이터베이스는 `Read Committed`를 기본 격리 수준으로 사용합니다. `Repeatable Read`가 아닌 `Read Committed`를 기본값으로 선택한 이유는 무엇일까요? **정합성과 동시성(성능)** 사이의 어떤 트레이드오프를 고려한 결정일까요?
    - 대부분의 애플리케이션 워크로드는 한 트랜잭션 내에서 똑같은 데이터를 여러 번 읽는 경우보다, 여러 사용자가 빠르고 끊김 없이 데이터를 읽고 쓰는 경우가 훨씬 많기 때문에 Repeatable Read에서 제공하는 정합성을 성능 저하를 감수하면서 이용할 필요가 없음

- ? **Q2.** MySQL의 InnoDB 엔진은 `Repeatable Read` 격리 수준에서 **갭 락(Gap Lock)**이라는 특별한 잠금 방식을 사용하여 팬텀 리드(Phantom Read)를 방지합니다. 이 갭 락은 어떤 원리로 동작하며, 이로 인해 발생할 수 있는 잠재적인 부작용은 무엇일까요?
    - 쿼리가 탐색한 범위 내에서 새로운 INSERT가 발생하지 않도록 기존 인덱스 간의 공간에 락을 거는 것
    - 잠재적인 부작용: 동시성 저하, 데드락 발생 가능성 증가

- ? **Q3.** MVCC(Multi-Version Concurrency Control, 다중 버전 동시성 제어)는 어떻게 낮은 격리 수준(예: `Read Committed`, `Repeatable Read`)에서 락(Lock)을 최소화하면서도 데이터의 일관된 읽기를 가능하게 할까요? 스냅샷(Snapshot)과 언두 로그(Undo Log)의 역할은 무엇일까요?
    - 스냅샷: 트랜잭션이 시작되는 시점
    - 언두로그: 데이터 변경 이력
    - 스냅샷을 기준으로 스냅샷 이후에 변경된 데이터는 언두로그를 참고해서 스냅샷 이전의 데이터로 복원해서 조회한다

* ? 벌크 업데이트시 베스트 프랙티스는?
    * 작은 배치 단위로 나누어 실행:
        * 수백만 건의 데이터를 하나의 `UPDATE` 문으로 처리하면, 하나의 거대한 트랜잭션이 발생하여 장시간 동안 테이블 전체에 락(Lock)이 걸릴 수 있습니다.
        * ? 격리레벨이 `REPEATABLE READ`인 경우에는 문제가 없을까?
            - ! `UPDATE`는 데이터를 변경하는 쓰기 작업이므로, 어떤 격리 수준에서든 변경하려는 행(row)에 **배타적 잠금(Exclusive Lock, X-Lock)**을 설정하여 다른 트랜잭션이 동시에 수정하는 것을 막습니다.
    - 관련 인덱스 및 제약 조건 임시 비활성화: 
        - 데이터가 업데이트될 때마다 관련된 모든 인덱스도 함께 수정되어야하는데 이는 매우 큰 부하를 유발함
    - 서비스 유휴 시간 활용 (새벽 배포)
    - 임시테이블 활용:
        - 매우 큰 테이블의 경우, 직접 `UPDATE`하는 대신 새로운 테이블을 만들어 교체하는 방식이 훨씬 빠르고 안전함
        - 무겁고 오래 걸리는 데이터 변경 작업이 서비스 중인 테이블이 아닌, 복제된 테이블에서 이루어지므로 서비스에 미치는 영향을 거의 완벽하게 차단할 수 있습니다.

##### NoSQL에서 사용되는 LSM-Tree

- ? 왜 대부분의 RDBMS는 B-Tree를, 쓰기 중심의 NoSQL은 LSM-Tree를 선택했을까요

- ? **Q3.** LSM-Tree는 여러 SSTable 파일을 주기적으로 병합하는 '컴팩션(Compaction)' 과정을 거칩니다. 이 컴팩션 과정은 왜 필요하며, 시스템에 어떤 영향을 미칠 수 있을까요? (예: Write Amplification, Read Amplification)

- ? mongodb는 내부엔진은 B+Tree의 특성을 따르면서도 어떻게 높은 쓰기 성능을 낼 수 있을까?
    - 관련된 데이터를 한곳에 모아두는 **'데이터 지역성(Data Locality)'**
    - 사용자는 메모리와 로그에 쓰는 빠른 작업만 경험하고, 느린 디스크 파일 수정 작업은 백그라운드에서 처리되므로 높은 쓰기 성능을 체감하게 됩니다.
    - 문서 수준 잠금을 통해 높은 동시성 보장
    - MongoDB는 개발자가 **데이터의 안정성과 쓰기 속도 사이에서 직접 트레이드오프를 선택**할 수 있는 '쓰기 보증(Write Concern)' 옵션을 제공
        - **빠른 쓰기 (w:1):** 데이터가 메인 서버의 메모리에만 기록되어도 성공으로 간주합니다. 가장 빠르지만, 서버가 갑자기 다운되면 데이터가 유실될 수 있습니다.
        - **안전한 쓰기 (w:"majority"):** 복제된 서버의 과반수 이상에 데이터가 기록되었음을 확인한 후 성공으로 간주합니다. 더 느리지만 훨씬 안전합니다.

##### etc

* ? "복합 인덱스(Composite Index)를 생성할 때, 컬럼의 순서는 왜 중요하며 어떤 기준으로 순서를 정해야 할까요?"
    - 복합 인덱스는 **가장 자주 사용되는 쿼리 패턴**을 분석하여, **데이터를 가장 효율적으로 좁혀나갈 수 있는 순서**로 컬럼을 배치해야 그 가치를 최대로 발휘할 수 있습니다.

|우선순위|기준|설명|
|---|---|---|
|**1**|**등호(=) 조건 컬럼**|조회 범위를 가장 확실하게 좁혀줍니다.|
|**2**|**카디널리티가 높은 컬럼**|더 적은 데이터만 남도록 효과적으로 필터링합니다.|
|**3**|**정렬(ORDER BY)에 사용되는 컬럼**|인덱스 순서와 정렬 순서가 일치하면 파일 정렬을 생략할 수 있어 성능이 향상됩니다.|
