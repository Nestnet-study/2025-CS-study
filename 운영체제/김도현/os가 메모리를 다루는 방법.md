
## 메모리 계층 구조

운영체제는 다층적인 메모리 계층 구조를 관리합니다:

1. **레지스터**: CPU 내부의 초고속 메모리
2. **캐시 메모리**: CPU와 주 메모리 사이의 고속 버퍼
3. **주 메모리(RAM)**: 프로그램이 실행되는 기본 작업 공간
4. **보조 메모리(하드 디스크, SSD 등)**: 비휘발성 저장 장치


메모리 관리라고 한다면 **사용자가 쉽게 메모리를 사용할 수 있게 도와주는 것**을 말한다.
또한 교착상태를 막기 위해 메모리를 보호하기도한다. 

메모리 관리는 사용자가 메모리를 쉽게 사용할 수 있도록 돕고, 교착상태 방지 등의 보호 기능을 제공하는 운영체제의 핵심 기능입니다.

## 링킹(Linking)

링킹은 기계어 파일과 라이브러리 파일을 연결하여 실행 가능한 파일로 만드는 과정입니다.

- **정적 링킹**: 코드 유출 방지와 시간 단축 장점이 있으나, 매 컴파일마다 공통 라이브러리를 포함시켜 메모리 낭비 발생
- **동적 링킹**: 공통 라이브러리를 하나만 메모리에 올려 여러 프로그램이 공유하여 메모리 효율적 사용, 단 오버헤드 발생

## 로딩(Loading)

로딩은 프로그램 실행 시 메모리에 파일(데이터)를 적재하는 과정입니다.

- **동적 적재(Dynamic Loading)**: 메모리가 프로세스보다 클 때 사용, 필요한 모듈만 메모리에 적재
- **오버레이 적재(Overlays Loading)**: 프로세스가 메모리보다 클 때 사용, 프로세스를 순차적으로 적재하나 수동 구현 필요
    - 이 단점을 보완하기 위해 OS가 자동 관리하는 **Paging**과 **VMM** 도입

## 스와핑(Swapping)과 VMM

- **스와핑**: 메모리 용량 초과 시 기존 프로세스를 보조기억장치로 내보내고(Swap Out) 새 프로세스 적재, 필요시 다시 가져옴(Swap In)
- **VMM(Virtual Machine Monitor)**: 스와핑과 유사하나 프로세스 단위가 아닌 페이지 단위로 메모리와 보조기억장치 간 교환 수행

## 바인딩(메모리 주소 할당)

프로그램의 논리적 주소를 물리적 메모리 주소로 변환하는 과정:

1. **컴파일 시 바인딩**: 물리 주소 직접 지정, 논리 주소와 물리 주소 동일
2. **로드 타임 바인딩**: 논리 주소(가상 주소) 사용, MMU가 매핑
3. **실행 타임 바인딩**: 현대적 방식, 하드웨어가 필요할 때마다 주소 변환 수행


# 1. 메모리 할당 
## MMU(Memory Management Unit)

MMU는 논리 주소를 물리 주소로 변환하고 메모리 보호 및 캐시 관리를 담당하는 하드웨어입니다.

- 메모리 보호를 위해 Limit 레지스터 활용, 접근 범위 초과 시 fault 발생

## 연속 할당 방식

프로세스를 메모리에 연속적으로 할당하는 방식:

1. **단일 프로그래밍(Uni)**: 한 번에 하나의 프로그램만 메모리에 적재
2. **다중 프로그래밍**:
    - **고정 분할 방식(MFT)**: 메모리를 미리 고정 크기로 나누어 할당, 내부 단편화 발생
    - **가변 분할 방식(MVT)**: 프로그램 크기에 맞게 동적 할당, 외부 단편화 발생

### 외부 단편화 문제와 해결책

- **외부 단편화**: 총 가용 공간은 충분하나 연속적이지 않아 새 프로세스 적재 불가
- **Compaction**: 가용 공간을 한쪽으로 모으는 방법, I/O 오버헤드 발생

### 메모리 할당 전략

- **최초 적합(First-fit)**: 처음 발견되는 충분한 공간에 할당, 속도 최적화
- **최적 적합(Best-fit)**: 프로세스 크기와 가장 근접한 공간 할당, 공간 최적화
- **최악 적합(Worst-fit)**: 가장 큰 가용 공간에 할당

## 불연속 할당 - 페이징(Paging)

프로세스를 고정 크기의 페이지로 분할하여 비연속적으로 메모리에 적재:

- 페이지 매핑 테이블을 통해 논리 주소와 물리 주소 연결
- 고정 크기 분할로 인해 내부 단편화 발생 가능하나, 외부 단편화보다 효율적
- 현대 운영체제에서 널리 사용되는 메모리 관리 기법

이상의 방법들을 종합적으로 활용하여 현대 운영체제는 효율적인 메모리 관리를 수행합니다.

 Compaction이라는 방법을 사용하면 Hole을 한쪽으로 공간을 모아줄 수 있습니다. 이때, 프로세스를 잠깐 보조기억장치에 복사해 붙여넣기하는데 보조기억장치는 느리기 때문에 I/O 문제가 발생할 수 있습니다.
![](https://i.imgur.com/ZIRY8fh.png)
### 프로세스는 어디에 넣는게 적합할까?

- 최초 적합(First-fit) : 메모리를 탐색하다 최초로 발견되는 공간에 할당하는 기법 (속도 최적)
- 최적 적합(Best-fit) : 모든 공간을 다 탐색하고 가장 적합한 공간에 넣는 기법 (공간 최적)
- 최악 적합(Worst-fit) : 불 필요한 공간에 넣는 기법(프로세스 크기 차이가 많이 나는 곳에 할당)



## 불연속 할당 - 페이징(Paging)

프로세스를 고정 크기의 페이지로 분할하여 비연속적으로 메모리에 적재:

- 페이지 매핑 테이블을 통해 논리 주소와 물리 주소 연결
- 고정 크기 분할로 인해 내부 단편화 발생 가능하나, 외부 단편화보다 효율적
- 현대 운영체제에서 널리 사용되는 메모리 관리 기법

이상의 방법들을 종합적으로 활용하여 현대 운영체제는 효율적인 메모리 관리를 수행합니다.

![](https://i.imgur.com/xzIMgzG.png)





# 2. 페이지 테이블의 성능 문제

페이지 매핑 테이블의 크기가 증가할 때 발생하는 주요 성능 문제:

- 페이지 매핑 테이블이 CPU의 MMU에 저장되어야 하지만 용량이 커지면 CPU에 과부하 발생
- 테이블 크기 증가로 디스크 접근 횟수가 많아져 성능 저하
- 메인 메모리에 저장할 경우 페이지 매핑 테이블과 메인 메모리를 두 번 참조해야 하는 문제 발생

## 캐시 메모리

캐시 메모리를 활용하면 성능 저하 없이 페이지 매핑 테이블을 효율적으로 관리할 수 있습니다.

### 캐시의 지역성 덕분

- 자주 사용하는 데이터를 캐시 메모리에 저장하여 주기억장치 접근 없이 빠르게 데이터 접근
- 메모리 참조와 접근 비용 감소
- 지역성의 두 가지 유형:
    - 시간 지역성: 일정 시간 동안 집중적으로 데이터 접근
    - 공간 지역성: 일정 위치에 집중적으로 데이터 접근

### 캐시 매핑 원리

- 캐시 히트(Cache Hit): 원하는 데이터가 캐시에 있어 빠르게 접근 가능
- 캐시 미스(Cache Miss): 원하는 데이터가 캐시에 없어 메모리에서 가져와야 함
![](https://velog.velcdn.com/images/dongwookang/post/0583d2a0-8f4a-4296-b4aa-64477dc3cd26/image.png)


# 3. 메모리에 데이터가 없다?

![](https://velog.velcdn.com/images/dongwookang/post/e64f8750-cfca-41ce-a452-6b91924936c1/image.png)

가상 메모리는 실제 필요한 데이터만 메인 메모리에 올리고 나머지는 하드 디스크에 저장하는 방식입니다.

## 요구 페이징 도중 페이지 폴트 발생
![](https://velog.velcdn.com/images/dongwookang/post/ada7f1e6-fb14-4a7c-bf84-53aba53ac3e3/image.png)
물리 메모리에 필요한 페이지가 없을 때 페이지 폴트(Page Fault)가 발생합니다:

1. CPU가 TRAP 발생시켜 운영체제에 제어권 전달
2. 운영체제가 가상 메모리에 페이지 존재 여부 확인
3. 물리 메모리 공간 확인
4. 디스크에서 메모리로 페이지 로드
5. 페이지 테이블 정보 업데이트

물리 메모리가 꽉 찬 경우, 페이지 교체 알고리즘을 통해 사용하지 않는 페이지를 디스크로 내보내고(스와핑) 새 페이지를 적재합니다.

## 페이지 교체 알고리즘을 이용한 스와핑으로 해결

- OPT(Optimal): 최적 교체로 가장 오랫동안 사용하지 않을 페이지 교체
- FIFO(First In First Out): 가장 먼저 올라온 페이지 제거
- LRU(Least Recently Used): 가장 오랫동안 사용되지 않은 페이지 제거
- LFU(Least Frequently Used): 사용 빈도가 가장 낮은 페이지 제거
- NUR(Not Used Recently): 최근 사용하지 않은 페이지 교체, 참조 비트와 변형 비트 활용

페이지 폴트가 많이 발생하면 CPU를 멈추는 일이 증가해 시스템 성능이 저하되므로(스레싱의 원인), 교체 알고리즘을 최적화하여 페이지 폴트를 최소화하는 것이 중요합니다.




참고: https://velog.io/@dongwookang/%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC