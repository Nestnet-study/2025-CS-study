1. 메모리 구조 - 로컬리티, 캐시, 메모리, virtual memeory
2. CPU 구조 - CPU 동작 방식, 레지스터, 명령어 처리 방식, 하자드
3. 시스템 버스를 포함한 컴퓨터의 전체적인 동작 과정 (+병렬처리)

---

### 메모리 구조

> 로컬리티, 캐시, 메모리, Virtual Memory

- 로컬리티
	- 시간적/물리적

- Virtual Memory의 장점
	- 프로세스 간 전환이 빨라짐 (전체 메모리를 한번에 교체하는 대신 TLB만 교체하고 메모리는 점진적으로 교체)
	- 물리적으로 실행이 불가능한 프로그램도 성능이 좀 느려지는 대신 실행이 가능해짐
	- 프로세스 간 메모리 침범을 하드웨어 레벨에서 즉시 차단할 수 있음
		- 차단 규칙은 OS에서 설정됨
	- 메모리 파편화 문제가 해결됨

- ? Virtual Memory는 소프트웨어로 구현되는건가?
	- 하드웨어 + 소프트웨어
	- 하드웨어 요소
		- MMU (Memory Management Unit)
			- OS가 설정해둔 Page Table을 참고해서 가상 주소를 물리주소로 변환
			- 현재 실행 중인 프로세스의 접근 권한 체크
		- TLB (Translation Lookaside Buffer)
	- 소프트웨어
		- Page Table 관리
		- Page Fault 핸들링
		- 메모리 보호 정책 설정
		- 스왑 관리

- ? 리눅스 같은 OS를 직접 구현할때 저런 하드웨어 요소들을 어떻게 컨트롤하나?
	- 언어 레벨에서 직접 제공되는 기능이 아니기 때문에 하드웨어 제어용 함수를 직접 구현해서 사용함
		- 레지스터 읽고 쓰기 / 메모리 직접 접근 / 특정 CPU 명령어 실행

- ? Virtual memory는 성능이 중요할때는 안 쓰나?
	- YES
	- HPC는 메모리 예측 가능성이 중요해서 사용하지 않는다
	- 리눅스 커널이나 운영체제는 물리 메모리에 고정해서 사용함 (mmap, pinned memory)

- ? 캐시 레이어가 상위계층일수록 크기가 작아지는 이유에는 가격 말고도 다른게 있을까? 예상되는건 물리적인 탐색 비용?
	- YES
	- 신호의 물리적인 전파 지연, 탐색 비용, 소모 전력 문제
	- 이 문제를 해결하기 위해 요즘 CPU 구조에서는 캐시 병렬 배치 등의 기술이 활용됨

- ? 캐시 주소는 메모리내 주소 + 캐싱내 주소 + 블록내 주소?
	- YES
	- Index로 캐시 슬롯 찾기
	- Tag로 검증하기 (hit/miss)
	- Offset으로 블록 내 데이터 접근

- ? Fully Associative Mapping은 Index가 없는건가?
	- YES
	- Direct Mapping : Index 당 캐시 슬롯 하나
	- Fully Associative Mapping : Index X
	- Set-Associative Mapping : Index 당 캐시 슬롯 여러개
		- 세트 내부 요소들은 하드웨어를 이용해서 병렬로 태그 일치 여부를 검사

- ? Direct Mapping에서는 capacity miss가 발생하지 않는다고 할 수 있을까? 만약 Index를 맵핑할때 비어있는 주소를 우선적으로 할당해주고, 비어있는 주소가 더 이상 없어서 새로운 데이터에 기존의 Index를 할당해준다면 Capacity miss 성격의 conflict miss가 발생한다고 할 수 있지 않을까?
	- Capacity Miss는 발생하지 않는다고 보는것이 맞다
	- Direct Mapping의 장점이 데이터를 기반으로 인덱스를 바로 결정할 수 있어서 탐색이 빠르다는건데 만약 비어있는 공간을 우선적으로 할당하게 한다면 Fully Associative Mapping과 다른바가 없다

- ? Fully Associative Mapping에서는 conflict miss가 발생하지 않다고 볼 수 있을까?
	- YES. Fully Associative Mapping에서는 Index가 없음

---

### CPU 구조

> CPU 동작 방식, 레지스터, 명령어 처리 방식, 하자드

- CPU 구성요소
	- 코어내부
		- ALU (산술논리연산장치) - 연산
		- CU (제어장치) - 제어 신호 생성
		- 레지스터 - 데이터 임시 저장
			- 범용 레지스터 <- 일반 프로그램이 접근 가능
			- 특수 목적 레지스터
				- PC(Program Counter)
				- IR(Instruction Register)
				- 상태/플래그 레지스터
				- 제어 레지스터
				- 세그먼트 레지스터
				- 등등
		- 캐시 메모리 (L1, L2 등 캐시)
	- 코어외부
		- L3 캐시: 코어간 공유 캐시
		- 메모리 컨트롤러: RAM과 직접 연결되는 컨트롤러
		- 인터커넥트: 통신 회로
		- 전력/클럭 관리 유닛
		- 내장 그래픽카드
		- I/O 유닛
		- PCIe 컨트롤러 

- CPU 동작방식
	- Fetch → Decode → Execute → Memory → Write Back
	- 스테이지마다 한개의 clock 사용
		- 파이프라인 단계 중 가장 오래 걸리는 단계의 지연 시간을 기준으로 결정

- ? 만약 파이프라인 단계 간 시간 차이가 크다면 어떤 구조적 개선이 가능할까?
	- 하드웨어 설계 최적화
	- super-pipelining
		- 느린 단계를 더 작은 하위 단계로 쪼개서 파이프라인을 더 깊게 만듦
		- 단점
			- 단계 수가 많아지면 파이프라인 하자드(충돌)도 더 복잡해짐
			- 딥 파이프라인은 분기 예측 실패 시 패널티가 커짐
	- Multi-Cycle Execution
		- 느린 연산만 여러 사이클로 나눠서 처리하고, 나머진 빠르게 돌림
		- ex. MIPS 다중 사이클 설계

- ? 명령어 해석이란 기계어에 맞춰서 물리적인 회로가 실제로 트리거되는건가?
	- YES
	- Decode는 소프트웨어적인 “해석”이 아니라 하드웨어 동작을 직접 지시하는 “신호 제어”
	- 구체적으로는 명령어 비트 → Control Unit(제어장치) → Control Signal(제어 신호) → CPU 내부 회로 트리거

- ? Control Unit은 어떻게 동작할까?
	- Hardwired Control + Microprogrammed Control
	- Microprogram
		- 하드웨어 레벨에서 제공해주는 API
		- 하드웨어가 알아서 일련의 연산으로 쪼개서 처리해줌 (별도의 소프트웨어 처리 불필요)

- ? 명령어를 하드웨어 처리 대신 마이크로코드 처리로 넘기는 기준은 어떻게 정할까?
	- 사용빈도
	- 동작의 복잡도
	- 하드웨어 비용
	- 설계 유연성 (확장성)
	- 명령어 세트 철학 (ISA Philosphy)
		- RISC
		- CISC

- ? RISC가 CISC보다 무조건 좋나?
	- YES
	- 과거에 CISC를 많이 사용했던 이유
		- 같은 연산을 하려면 더 많은 명령어를 써야 하기 때문에 프로그램 코드가 길어짐 → 명령어 캐시(ICache) 부담이 커짐 → 메모리 사용량, 캐시 미스 확률이 올라감
		- 복잡한 연산도 명령어 레벨에서 지원해줘서 어셈블리 코드 짤때 편리함
	- 하지만.. 현재는
		- 하드웨어의 발달로 기본적인 메모리 용량이 늘어남
		- RISC + Compressed 명령어 셋을 통해서 메모리 소모 자체를 줄이는 기술도 등장함
		- 컴파일러의 최적화 성능이 강력해져서 굳이 어셈블리 레벨에서 코딩할 필요가 없어짐
	- 따라서 RISC가 하드웨어 측면에서 압도적임
	- 하지만 기존에 CISC 기반으로 생태계가 이미 구성되었던 상황이라 CISC가 완전히 사라지기는 어렵다
		- CISC 호환성을 유지하면서 내부적으로 CISC 명령어를 RISC 스타일로 디코딩해서 사용하는 방식으로 변화하고있음

- ? M1 chip이 혁신이었던 이유?
	- SoC (System on Chip)
		- CPU + GPU + 메모리 + 기타 컴포넌트를 하나로 통합 (SoC)
		- M1 이전에도 SoC화가 진행되고 있었지만 메모리까지 CPU에 통합한건 M1이 최초
		- UMA (Unified Memory Architecture) 가능해짐
		- 메모리 접근, 데이터 이동 속도가 엄청나게 빨라짐
		- 
	- ARM RISC 기반이라 저전력 고성능
	- 고성능 코어 + 고효율 코어
		- 효율적인 전력 사용 + 성능

- ? M1 chip에서 x86 프로그램을 돌리기 위한 rosetta 동작원리?
	- 명령어 단위로 해석 (CISC -> RISC)
	- 정적분석 / 동적분석

- ? 모든 프로그램을 Rosseta로 번역할 수 없는 이유?
	- 일반 명령어는 거의 100% 변환가능
	- 하지만 일반 프로그램에서는 시스템콜도 사용하게되는데 시스템콜은 결국 하드웨어나 운영체제에 의존적이라 번역이 불가능한 경우가 존재함
		- ex. 커널 권한 문제 (KEXT)

- ? 프로그램을 실행할때 OS가 영향을 미치는 범위는 어디까지인가? 예를 들어 IR에 들어간 명령어를 실행할때 OS를 거치는가?
	- 특히 Microprogrammed Control 방식일때 어떻게?
	- 하드웨어 레벨에서 명령어를 해석해서 실행

- ? 그럼 RISC에서는 어떤 명령어들이 하드웨어 레벨에서 Microprogram으로 쪼개져서 실행될까?
	- 기본적으로 RISC는 컴파일 단계에서 단순한 명령어로 쪼개져서 하드웨어 레벨에서 연산을 쪼개는 작업이 불필요
		- 하드웨어 최적화에 유리한 이유
	- 하지만 몇가지 예외케이스가 존재함
		- 복잡한 메모리 접근
			- ex. 2개 이상의 block에 걸쳐있는 데이터
		- page fault같은 예외처리
		- 구형 RISC의 경우 곱셈/나눗셈
			- 요즘은 별도의 회로를 사용

- 하자드의 종류 3가지
	- 데이터 하자드
		- 명령어간 데이터 의존성
		- Forwarding
		- Stall
	- 제어 하자드
		- 분기 명령어 다음에 어떤 명령어가 올지 실행하기 전까지는 알수없음
		- 해결방법
			- Branch Prediction
			- Delayed Branch
	- 구조 하자드
		- 하드웨어 자원을 동시에 요구하면서 충돌
		- 하드웨어 리소스 추가
		- 파이프라인 단계 분리 최적화

- ? Hazard는 꼭 멀티 쓰레드가 아니더라도 Fetch가 일어날때 이전 명령어가 디코드 되고 있고 이런식으로 여러 개의 명령어가 각기 다른 단계에서 동시에 처리되고 있기 때문에 발생하는건가
	- YES

- ? CPU 내부 구조 하자드는 서로 다른 프로그램에서 동일한 자원을 점유하려고 할때 발생하는건가?
	- No
	- 그건 OS 레벨에서의 자원 충돌
	- 구조 하자드는 기본적으로 동일한 프로그램내에서 발생하는 문제
		- 스레드 간에 전환이 발생하면 파이프라인을 깨끗하게 비우고 레지스터 값도 해당 스레드의 컨텍스트로 갈아치우기 때문에 서로 다른 스레드 간의 명령어끼리 충돌할 일이 없다
		- SMT/Hyper-Threading의 경우에는 다른 프로그램 명령어 간에 충돌 발생 가능

- ? 실행되는 명령어는 한번에 하나 아닌가? 어떻게 구조 하자드가 발생하지
	- 구조 하자드는 “완전히 동시에” 두 명령어가 Memory Stage에 진입하려고 하는 게 아니라, “이전 명령어가 아직 Memory Stage를 점유하고 있는 상태에서” 다음 명령어가 Memory Stage에 진입하려고 할 때 발생하는 거
	- 따라서 다음과 같은 방법으로 해결가능
		- 메모리 액세스 포트를 복제하거나
		- Load/Store Queue 같은 중간 버퍼를 두거나
		- 명령어 스케줄러가 명령어 순서를 바꿔서 대기를 피하는 식으로 최적화를 한다.

- ? 전환하기전에 이전 명령어에서 메모리 자원 해제가 먼저 일어날때까지 기다렸다가 다음 명령어에 메모리 자원을 할당하는 방식으로도 해결할 수 있지 않을까? 이렇게 구현하려면 기다리는 시간 때문에 오버헤드가 너무 커지려나
	- YES
	- 가장 구현이 간단한 방식이지만 현재는 stall로 인한 오버헤드가 너무 커져서 사용되지 않는 방식
		- 과거에 CPU 속도가 메모리보다 느렸을때는 그렇게 구현하기도 했었음


---
### 시스템 버스를 포함한 컴퓨터의 전체적인 동작 과정 (+병렬처리)

- 컴퓨터의 기본 구성 요소
	- CPU - 연산 & 제어
		- ALU (Arithmetic-Logic Unit) - 연산
		- CU (Control Unit) - 제어 신호 생성
		- 레지스터 - 데이터 임시 저장
		- 캐시메모리
	- 메모리 - 프로그램 & 데이터
	- 입출력장치 - 외부세계와 컴퓨터 연결
	- 시스템 버스
		- 데이터 버스 - 데이터 전달
		- 주소 버스 - 메모리나 I/O 장치의 위치 지정
		- 제어 버스 - 읽기/쓰기 등 제어 신호 전달

- 전체 동작 과정
	1. 프로그램 적재
		1) 프로그램 작성 & 컴파일
		2) 프로그램 실행 -> OS가 새로운 프로세스 생성
			- 프로세스 테이블 등록
			- PCB(Process Control Block) 생성
				- 프로세스의 모든 상태를 담고 있는 핵심 자료구조
					- 프로세스 식별자
					- 프로세스 상태
					- 레지스터 상태 (Context)
					- 메모리 관리 정보
					- CPU 스케줄링 정보
					- I/O 상태 정보
					- 회계 정보 (CPU 사용 시간, 프로세스 실행에 쓴 자원량 등)
		3) 적재
			- 프로그램을 메인 메모리에 적재하는 과정
				- 코드 - 텍스트 영역)
				- 데이터 - 초기화된 전역/정적 변수
				- BSS(Block Started by Symbol) - 초기화 안 된 전역/정적 변수
				- 스택/힙 영역 할당
			- 정적 적재 vs 동적 적재
				- 정적 적재: 프로그램 전체를 메모리에 올리는 전통적인 방식
				- 동적 적재: 필요한 부분만 우선적으로 적재
					- 핵심 기술: 가상 메모리 + Demand Paging
					- 실행파일 헤더 정보만 보고 “진입점” 부분만 올리고, 나머지는 실행 도중에 점점 올리는 식
		4) 프로세스 상태 변경 & CPU 스케쥴링 큐에 등록
	2. 스케쥴러가 프로세스에 CPU 할당
		- 스케쥴러가 PCB에서 Context 정보를 CPU 레지스터에 복원
	3. Fetch
		1) CPU 캐시 메모리 확인
			1) 만약 캐시가 없으면 버스에 신호 전달
				- 주소버스: PC에 저장된 값
				- 제어버스: 읽기신호
				- 데이터베스: X
			2) 컴퓨터 구성 요소들은 신호를 전달받고 주소 디코딩
				- 각 장치는 자기 주소 범위에 해당하는지 판단해서 반응 여부 결정
			3) 메인 메모리에서 해당 신호를 받고 데이터버스에 데이터 전달
				- 만약 Page Fault가 발생하면 OS가 개입해서 하드디스크(스토리지)까지 요청이 내려감
			4) CPU 내부의 캐시 컨트롤러가 데이터버스에서 명령어를 읽어와서 CPU 내부 캐시에 저장
		2) CPU 캐시 메모리에서 읽어온 값을 IR에 적재
		3) PC 값 업데이트
			- 고정길이 명령어 -> 고정된 offset(명령어 길이)만큼 PC 증가
			- 가변길이 명령어 -> 디코딩 후 실제 명령어 길이를 계산해서 그만큼 PC 증가
		
		- ? 만약 레지스터 캐시에서 miss가 발생하면 1 clock안에 안 끝나는거 아닌가?
			- Yes
			- 따라서 해당 시간동안 파이프라인 stall이 발생함
			- 최적화를 위해서 다양한 개념이 고안됨
				- Branch Predictor: 분기될 거 같은 명령어 예측
				- Pre-fetch: 앞으로 쓸 명령어 미리 캐시에 가져다두기
	4. Decode
		1) IR에 들어있는 명령어를 비트 단위로 분해
		2) 명령어 해석
			- Opcode 해석: 실행할 연산 종류를 판단하고 필요한 실행 유닛 선택
			- Operand 해석: 레지스터 지정, 메모리 주소 계산 등 오퍼랜드 정보 추출
		3) 해석결과에 따라 CU가 제어 신호 생성

		- ! 이때 CISC, RISC에 따라 차이가 많이 발생함
			- RISC는 1사이클에 끝남
			- CISC는 복수사이클, 파이프라인 디코더 사용
	5. Execute
		- CU가 생성한 제어 신호에 따라 실제 CPU 구성 요소들이 연산을 수행
			- ALU 연산
			- 주소 계산
			- 분기 명령어 처리
			- 특수 연산 (인터럽트, 시스템 콜 등)
	6. 메모리/입출력
		- 메모리 읽기/쓰기
		- I/O 장치 접근
			- RISC -> I/O 장치도 메모리 주소 공간안에 배치해서 메모리처럼 접근
			- CISC -> 특별한 명령어로 I/O 포트에 접근
	7. 결과 저장
		- 실행 결과를 레지스터에 기록하는 단계
		- 메모리 읽기의 경우 메모리에서 가져온 데이터가 임시 버퍼에 대기중
		

- ? 64비트 주소 버스를 사용한다면 이론상 최대 몇 GB 메모리까지 지원가능?
	- 약 17억 GB
	- 메인보드, OS, 메모리 컨트롤러의 한계가 먼저 옴
	- 따라서 실제로 64비트 컴퓨터들도 64비트 주소까지 지원하진 않음

- ? 32비트 컴퓨터의 경우, 주소 버스보다 메모리크기가 커질수있는데 이러면 그냥 버려지나?
	- No. 이를 극복하기 위해 다양한 기술들이 등장
	- PAE
	- 뱅크 스위칭
	- 페이징/세그먼트
	- 메모리 매핑 I/O

- ? 임베디드 시스템은 메모리도 작은경우가 많아서 사실상 PAE나 메모리 뱅크는 더이상 안쓰이려나
	- YES
	- MPU(Memory Protection Unit), MMU(Memory Management Unit) 같은 장치를 써서 가상 메모리 관리하거나 I/O 매핑
	- 더 성능이 중요해지면 64비트 머신 사용
